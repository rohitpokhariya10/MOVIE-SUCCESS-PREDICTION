#Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.naive_bayes import GaussianNB

#Importing the data set
dataset = pd.read_csv("datasetfinal.csv")

# Split dataset into X (independent variable ) and y (dependent variable)
X = dataset.iloc[:, :-1].values #loc/iloc
y = dataset.iloc[:, 11].values

# Encoding categorical data
# Encoding the Independent Variable
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
number = LabelEncoder()
nameencoder=LabelEncoder()
actor1encoder=LabelEncoder()
actor2encoder=LabelEncoder()
actor3encoder=LabelEncoder()
genresencoder=LabelEncoder()
imdbscoreencoder=LabelEncoder()
budgetencoder=LabelEncoder()
grossencoder=LabelEncoder()
profitencoder =LabelEncoder()

#Encoding each categorical features. 
dataset['director_name'] = nameencoder.fit_transform(dataset['director_name'])
dataset['actor_1_name'] = actor1encoder.fit_transform(dataset['actor_1_name'])
dataset['actor_2_name'] = actor2encoder.fit_transform(dataset['actor_2_name'].astype(str))
dataset['actor_3_name'] = actor3encoder.fit_transform(dataset['actor_3_name'].astype(str))
dataset['genres'] = genresencoder.fit_transform(dataset['genres'])

# dataset['imdb_score'] = imdbscoreencoder.fit_transform(dataset['imdb_score'])
# dataset['budget'] = budgetencoder.fit_transform(dataset['budget'])
# dataset['gross'] = grossencoder.fit_transform(dataset['gross'])
# dataset['profit_percent'] = profitencoder.fit_transform(dataset['profit_percent'])
# Deal with all features. You skipped actor_2_name, actor_3_name. Take care of missing datas in actor_2 and actor_3.
features = ["director_name", "actor_1_name", "genres","imdb_score","budget","gross","profit_percent"]

# Encoding the Dependent Variable
labelencoder_y = LabelEncoder()
y = labelencoder_y.fit_transform(y)

# Splitting the dataset into the Training set and Test set

from sklearn.model_selection import train_test_split 
X_train, X_test, y_train, y_test = train_test_split(dataset[features], y, test_size = 0.2, random_state = 0) 
# test_size = 0.2 means 20% data is in test set
# random_state = 0 means it will generate same test set and train set


from sklearn.preprocessing import StandardScaler
# Scalind the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Create a Gaussian Classifier
model = GaussianNB()

# Train the model using the training sets
model.fit(X_train, y_train)

# predict values using the training data
nb_predict_train = model.predict(X_test)

# import the performance metrics library
from sklearn import metrics



#Predict Output 
# During training we have given features ["director_name", "actor_1_name", "genres","imdb_score","budget","gross","profit_percent"]
# So to predict provide same fearures in same order. 


actor_name= input("Director Name        : ")
director_name= input("Actor Name           : ")
genre= input("Genre                : ")
imdb_rating= float(input("IMDB Rating          : "))
budget= float(input("Budget               : "))
gross= float(input("Gross                : "))
profit_percent= float(input("Profit Percentage   : "))

predict=[actor_name,director_name,genre,imdb_rating,budget,gross,profit_percent]

# Convert categorical features to numerical using the encoders
predict = [nameencoder.transform([predict[0]])[0], 
           actor1encoder.transform([predict[1]])[0],
           genresencoder.transform([predict[2]])[0],
           predict[3], predict[4], predict[5], predict[6]] 

# Scale the numerical features
predict = scaler.transform([predict]) # Keep the [ ] to pass it as 2D array
prediction = model.predict(predict)


if prediction == 1:
    print("                           HIT")
else:
    print("                           FLOP")
    
          
# Accuracy
print("                             ACCURACY: {0:.4f}".format(metrics.accuracy_score(y_test, nb_predict_train)))
print()
